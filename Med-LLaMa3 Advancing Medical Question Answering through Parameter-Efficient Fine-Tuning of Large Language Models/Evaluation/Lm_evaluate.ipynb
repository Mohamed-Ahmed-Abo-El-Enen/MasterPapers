{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xM-Nzy50z_1_",
    "outputId": "b0427b22-f7d0-4160-cb06-93a796ea6da2"
   },
   "outputs": [],
   "source": [
    "# !pip install lm_eval\n",
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n_52EOkd0iox"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1O1i2UN52si-"
   },
   "outputs": [],
   "source": [
    "HF_API_KEY = \"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\"\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = HF_API_KEY\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cAvuYq7XSD_s"
   },
   "outputs": [],
   "source": [
    "# !git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QzQhYpVVwVRb"
   },
   "outputs": [],
   "source": [
    "# !hf auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DhH0S8huFRjH"
   },
   "outputs": [],
   "source": [
    "# !git clone https://huggingface.co/MohamedAhmedAE/Llama-3.2-3B-Instruct-Medical-Finetune-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path= None\n",
    "model_name = \"m42-health/Llama3-Med42-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0egH6CF0ye49"
   },
   "outputs": [],
   "source": [
    "# adapter_path= \"MohamedAhmedAE/Llama-3.1-8B-Instruct-Medical-Finetune-v3\" \n",
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# adapter_path= \"MohamedAhmedAE/Llama-3.2-3B-Instruct-Medical-Finetune-v4\" \n",
    "# model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# adapter_path= \"MohamedAhmedAE/Llama-3.2-1B-Instruct-Medical-Finetune-v4\" \n",
    "# model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4ZCKgFsIFQLW"
   },
   "outputs": [],
   "source": [
    "# !ls ~/.cache/huggingface/hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Uy64i4QyFStf"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/Llama-3.2-3B-Instruct-Medical-Finetune-v4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fdzHNsuCX93h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "\n",
    "def run_mmlu_evaluation(\n",
    "    model_name,\n",
    "    output_dir=\"./mmlu_results\",\n",
    "    batch_size=8,\n",
    "    device=\"cuda\",\n",
    "    dtype=\"float16\",\n",
    "    log_samples=True,\n",
    "    specific_tasks=None,\n",
    "    quantization=None,  # \"8bit\" or \"4bit\"\n",
    "    num_fewshot=5,      # few-shot parameter\n",
    "    adapter_path=None   # NEW: support PEFT adapters\n",
    "):\n",
    "    \"\"\"\n",
    "    Run MMLU evaluation using EleutherAI's lm-eval-harness.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Hugging Face model ID (base model).\n",
    "        output_dir (str): Where to save results.\n",
    "        batch_size (int): Evaluation batch size.\n",
    "        device (str): Device (cuda / cpu).\n",
    "        dtype (str): Data type (e.g., \"float16\").\n",
    "        log_samples (bool): Save individual predictions.\n",
    "        specific_tasks (list or str): Subset of tasks (default: \"mmlu\").\n",
    "        quantization (str): \"8bit\" or \"4bit\" quantization.\n",
    "        num_fewshot (int): Number of few-shot examples.\n",
    "        adapter_path (str): Optional LoRA/PEFT adapter path.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Build model_args\n",
    "    if quantization == \"8bit\":\n",
    "        model_args = f\"pretrained={model_name},load_in_8bit=True,dtype={dtype}\"\n",
    "    elif quantization == \"4bit\":\n",
    "        model_args = (\n",
    "            f\"pretrained={model_name},load_in_4bit=True,dtype={dtype},\"\n",
    "            \"bnb_4bit_compute_dtype=float16,\"\n",
    "            \"bnb_4bit_use_double_quant=True,\"\n",
    "            \"bnb_4bit_quant_type=nf4\"\n",
    "        )\n",
    "    else:\n",
    "        model_args = f\"pretrained={model_name},dtype={dtype}\"\n",
    "\n",
    "    # If using LoRA/PEFT adapter\n",
    "    if adapter_path:\n",
    "        model_args += f\",peft={adapter_path}\"\n",
    "\n",
    "    # Build command\n",
    "    cmd = [\n",
    "        \"lm_eval\",\n",
    "        \"--model\", \"hf\",\n",
    "        \"--model_args\", model_args,\n",
    "        \"--batch_size\", str(batch_size),\n",
    "        \"--device\", device,\n",
    "        \"--output_path\", output_dir,\n",
    "        \"--num_fewshot\", str(num_fewshot),\n",
    "    ]\n",
    "\n",
    "    # Add tasks\n",
    "    if specific_tasks:\n",
    "        if isinstance(specific_tasks, str):\n",
    "            cmd.extend([\"--tasks\", specific_tasks])\n",
    "        else:\n",
    "            cmd.extend([\"--tasks\", \",\".join(specific_tasks)])\n",
    "    else:\n",
    "        cmd.extend([\"--tasks\", \"mmlu\"])\n",
    "\n",
    "    # Log samples if requested\n",
    "    if log_samples:\n",
    "        cmd.append(\"--log_samples\")\n",
    "\n",
    "    # Debug info\n",
    "    print(f\"Running command: {' '.join(cmd)}\")\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    if adapter_path:\n",
    "        print(f\"Using adapter: {adapter_path}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"Quantization: {quantization or 'None'}\")\n",
    "    print(f\"Few-shot setting: {num_fewshot}-shot\")\n",
    "\n",
    "    # Run evaluation\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        print(\"✅ Evaluation completed successfully!\")\n",
    "        print(result.stdout)\n",
    "\n",
    "        # Save logs for reproducibility\n",
    "        log_path = os.path.join(output_dir, \"run_log.json\")\n",
    "        with open(log_path, \"w\") as f:\n",
    "            json.dump(\n",
    "                {\n",
    "                    \"command\": \" \".join(cmd),\n",
    "                    \"stdout\": result.stdout,\n",
    "                    \"stderr\": result.stderr,\n",
    "                },\n",
    "                f,\n",
    "                indent=2,\n",
    "            )\n",
    "        print(f\"Logs saved to {log_path}\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ Error running evaluation\")\n",
    "        print(f\"stderr: {e.stderr}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I-CGijL98d_Y"
   },
   "outputs": [],
   "source": [
    "def load_and_display_results(output_dir):\n",
    "    \"\"\"Load and display evaluation results\"\"\"\n",
    "    results_file = os.path.join(output_dir, \"results.json\")\n",
    "\n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MMLU EVALUATION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Display overall results\n",
    "        if 'results' in results:\n",
    "            for task, metrics in results['results'].items():\n",
    "                if 'acc' in metrics:\n",
    "                    accuracy = metrics['acc'] * 100\n",
    "                    print(f\"{task}: {accuracy:.2f}%\")\n",
    "\n",
    "        # Calculate average if multiple tasks\n",
    "        if 'results' in results and len(results['results']) > 1:\n",
    "            accuracies = [metrics.get('acc', 0) for metrics in results['results'].values()\n",
    "                         if 'acc' in metrics]\n",
    "            if accuracies:\n",
    "                avg_accuracy = sum(accuracies) / len(accuracies) * 100\n",
    "                print(f\"\\nAverage Accuracy: {avg_accuracy:.2f}%\")\n",
    "\n",
    "        print(\"=\"*50)\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"Results file not found: {results_file}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbNvmS3c0maK",
    "outputId": "f0fbc355-fb59-4e6e-a831-11c267252601"
   },
   "outputs": [],
   "source": [
    "# # Run evaluation with corrected task specification\n",
    "# success = run_mmlu_evaluation(\n",
    "#     output_dir=\"./mmlu_results\",\n",
    "#     model_name=model_name,\n",
    "#     adapter_path=adapter_path,\n",
    "#     batch_size=1,\n",
    "#     device=\"cuda\",\n",
    "#     dtype=\"float16\",\n",
    "#     log_samples=True,\n",
    "#     specific_tasks=\"mmlu_clinical_knowledge\",  # This will now be handled correctly\n",
    "#     quantization=\"8bit\",\n",
    "#     num_fewshot=0\n",
    "# )\n",
    "\n",
    "# if success:\n",
    "#     # Load and display results\n",
    "#     load_and_display_results(\"./mmlu_results\")\n",
    "# else:\n",
    "#     print(\"Evaluation failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nl2lvz3_S3yn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4F7lCdDIwhMd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrzF3hwdFVvk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c5r_EIQuX--N"
   },
   "outputs": [],
   "source": [
    "def evaluate_specific_subjects(model_name, adapter_path):\n",
    "    \"\"\"Example for evaluating specific MMLU subjects\"\"\"\n",
    "\n",
    "    # Common MMLU subjects\n",
    "    subjects = [\n",
    "        \"mmlu_anatomy\",\n",
    "        \"mmlu_clinical_knowledge\",\n",
    "        \"mmlu_college_biology\",\n",
    "        \"mmlu_college_medicine\",\n",
    "        \"mmlu_medical_genetics\",\n",
    "        \"mmlu_nutrition\",\n",
    "        \"mmlu_professional_medicine\",\n",
    "        \"mmlu_virology\",\n",
    "    ]\n",
    "    \n",
    "    success = run_mmlu_evaluation(\n",
    "        model_name=model_name,\n",
    "        adapter_path=adapter_path,\n",
    "        output_dir=\"./mmlu_specific_subjects\",\n",
    "        batch_size=1,\n",
    "        specific_tasks=subjects\n",
    "    )\n",
    "\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMeXnhZS8FVu",
    "outputId": "faccd0c0-82e9-479f-a51d-45b15b35cb07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: lm_eval --model hf --model_args pretrained=m42-health/Llama3-Med42-8B,dtype=float16 --batch_size 1 --device cuda --output_path ./mmlu_specific_subjects --num_fewshot 5 --tasks mmlu_anatomy,mmlu_clinical_knowledge,mmlu_college_biology,mmlu_college_medicine,mmlu_medical_genetics,mmlu_nutrition,mmlu_professional_medicine,mmlu_virology --log_samples\n",
      "Evaluating model: m42-health/Llama3-Med42-8B\n",
      "Output directory: ./mmlu_specific_subjects\n",
      "Quantization: None\n",
      "Few-shot setting: 5-shot\n",
      "✅ Evaluation completed successfully!\n",
      "hf (pretrained=m42-health/Llama3-Med42-8B,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n",
      "|        Tasks        |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|---------------------|------:|------|-----:|------|---|-----:|---|-----:|\n",
      "|anatomy              |      1|none  |     5|acc   |↑  |0.6963|±  |0.0397|\n",
      "|clinical_knowledge   |      1|none  |     5|acc   |↑  |0.7660|±  |0.0261|\n",
      "|college_biology      |      1|none  |     5|acc   |↑  |0.8125|±  |0.0326|\n",
      "|college_medicine     |      1|none  |     5|acc   |↑  |0.6705|±  |0.0358|\n",
      "|medical_genetics     |      1|none  |     5|acc   |↑  |0.7600|±  |0.0429|\n",
      "|nutrition            |      1|none  |     5|acc   |↑  |0.7288|±  |0.0255|\n",
      "|professional_medicine|      1|none  |     5|acc   |↑  |0.7500|±  |0.0263|\n",
      "|virology             |      1|none  |     5|acc   |↑  |0.4940|±  |0.0389|\n",
      "\n",
      "\n",
      "Logs saved to ./mmlu_specific_subjects/run_log.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_specific_subjects(model_name, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srzYYjVT86HT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27fEMm7Bzd6v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
